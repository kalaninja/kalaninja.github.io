[{"authors":["admin"],"categories":null,"content":"My name is Alexander Kalankhodzhaev, MSc in Computer Science. I work as a TechLead of the blockchain lab of the largest Russian oil company. I am a developer, a big fan of computer technologies, an amateur racer and a father of two kids.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"My name is Alexander Kalankhodzhaev, MSc in Computer Science. I work as a TechLead of the blockchain lab of the largest Russian oil company. I am a developer, a big fan of computer technologies, an amateur racer and a father of two kids.","tags":null,"title":"Alexander Kalankhodzhaev","type":"authors"},{"authors":[],"categories":["Go"],"content":"A powerful language integrated query (LINQ) library for Go.\n Written in vanilla Go, no dependencies! Complete lazy evaluation with iterator pattern Safe for concurrent use Supports generic functions to make your code cleaner and free of type assertions Supports arrays, slices, maps, strings, channels and custom collections  ","date":1570904081,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570904081,"objectID":"efb6a0a0e2802f4f76c7789f1ad1e7df","permalink":"/project/go-linq/","publishdate":"2019-10-12T21:14:41+03:00","relpermalink":"/project/go-linq/","section":"project","summary":"A powerful language integrated query (LINQ) library for Go","tags":["go-linq","golang"],"title":"go-linq","type":"project"},{"authors":null,"categories":["Algorithms"],"content":"This time I want to show how to solve a game using a perfect play which means being able to predict the outcome of the game from any position. The perfect play is the strategy that leads to the best possible outcome for that player regardless of the response by the opponent. For the illustration I have selected two children’s games with stones. The rules are very simple. There is a pile of 99 stones. Two player take n stones out of the pile in turn. The one who takes the last stone is the winner. In each game n is different:\n it is in the closed interval between 1 and 3 power of 2  Let’s find out how to always win these kind of games.\nProblem identification As both games are very similar I will talk about them as a single one. This is a game of two players with only two possible outcomes; either one or the other of the players wins, no draw is possible. So, this is a strictly competitive finite two-person game. As players move in turns and each player at all times is aware of all the events that have previously occurred, this is a game of perfect information. According to Zermelo’s theorem\n Any finite two-person game of perfect information in which the players move alternatingly and in which chance does not affect the decision making process, if the game cannot end in a draw, then one of the two players must have a winning strategy\n The algorithm Now that we know the type of problem we are dealing with this leads us to the main question of how to analyze the game. The answer is to model the game, which is to build a tree of all possible decisions made by both players over time. This tree is usually called a game tree whose nodes are positions in a game and whose edges are moves. With this tree it is possible to solve the game using backward induction. Backward induction is an extremely powerful technique that has been applied not just to games but also to many other problems in computer science. It is sometimes known as Zermelo’s algorithm, named after Professor Ernst Zermelo, who used it to analyze the game of chess. The idea is very simple: to traverse the game tree in reverse order from leaves (endgame states) to the root (initial state) each time assuming the current move-making player is choosing what is best for himself. Here is a small example. Let’s assume that we are playing a television game show quiz. There is given a set of possible subjects, e.g. { Algebra, Biology, Chemistry, Drama}. Each participant in turn chooses a subject that he doesn’t want to answer and it disappears from the list. For example, there are 3 players with their own preferences (in descending order):   Player 1 Player 2 Player 3    A C D  B A B  C B C  D D A   \nThe straightforward way First of all lets try to solve the situation in a straightforward manner. So, Player 1 is getting rid of subject D, Player 2 – B (D is already removed), Player 3 – A. The result is – C (Chemistry), which is not so good for Player 1. Now let’s solve it the other way.\nBackward induction First we need to build a complete game tree.  Then, assuming the fact that Player 3, who is making the last choice, always chooses what is best for himself, the tree can be reduced to the following  The same assumption for Player 2  When the tree is fully reduced we can see that Player 1 is really choosing only between B and C and furthermore if he wants to get a better result in the end he has to sacrifice a better option in the beginning.\nCoding Now back to our problem. Let’s code the backward induction algorithm using java this time. First, we need to store the changing state of the game.\nimport java.util.ArrayList; import java.util.List; public class State { private int stoneCount; public State(int stoneCount) { this.stoneCount = stoneCount; } public List\u0026lt;State\u0026gt; getNextStates() { List\u0026lt;State\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(3); result.add(new State(stoneCount - 1)); result.add(new State(stoneCount - 2)); result.add(new State(stoneCount - 3)); return result; } public int getStoneCount() { return stoneCount; } public boolean isTerminated() { return stoneCount \u0026lt;= 3; } @Override public String toString() { return String.valueOf(stoneCount); } }  Then the game tree. Each node contains the current state, boolean field that shows if the current player is able to win in the current state, and the next state that will come after the chosen move.\npublic class Node { private State state; private boolean currentPlayerWins; private Node nextNode; public Node(State state) { this.state = state; } public State getState() { return state; } public boolean getCurrentPlayerWins() { return currentPlayerWins; } public void setCurrentPlayerWins(boolean currentPlayerWins) { this.currentPlayerWins = currentPlayerWins; } public void setNextNode(Node nextNode) { this.nextNode = nextNode; } @Override public String toString() { String result = String.format(\u0026quot;{%s | %s}\u0026quot;, state, currentPlayerWins); if (nextNode != null) { result += String.format(\u0026quot; -\u0026gt; %s\u0026quot;, nextNode); } return result; } }  The last thing that we need is the worker that will build and reduce the game tree. Here we need to do some tricks. First of all don’t try to store the complete tree in memory, because you will need to allocate 56343125079040471808818753 nodes. I bet that you will run out of memory pretty soon. Instead, we might generate only the winning subtrees, because a single winning subnode is enough to treat the previous node as winning. Another thing is that though the amount of nodes is enormous, the amount of possible states is limited to between 1 and 99, and no matter how you get to it either straight from 99 to 96, or following the path 99 -\u0026gt; 98 -\u0026gt; 96, if the current player is able to win from state 96 in the first branch, he wins from this state in the second. So, cache can be used to store results for states that have already been calculated.\nimport java.util.Collections; import java.util.HashMap; import java.util.List; import java.util.Map; public class TreeWorker { private final Map\u0026lt;Integer, Node\u0026gt; cache = new HashMap\u0026lt;\u0026gt;(); public Node generateTree(State initialState) { Node root = new Node(initialState); generateSubTree(root); return root; } private void generateSubTree(Node node) { if (node.getState().isTerminated()) { node.setCurrentPlayerWins(true); return; } Node nextNode = null; List\u0026lt;State\u0026gt; states = node.getState().getNextStates(); Collections.shuffle(states); for (State state : states) { nextNode = cache.get(state.getStoneCount()); if (nextNode == null) { nextNode = new Node(state); generateSubTree(nextNode); cache.put(nextNode.getState().getStoneCount(), nextNode); } if (!nextNode.getCurrentPlayerWins()) { break; } } node.setCurrentPlayerWins(!nextNode.getCurrentPlayerWins()); node.setNextNode(nextNode); } }  For the second game (with powers of 2) we need to slightly modify the State class\nimport java.util.ArrayList; import java.util.List; public class State { private int stoneCount; public State(int stoneCount) { this.stoneCount = stoneCount; } public List\u0026lt;State\u0026gt; getNextStates() { List\u0026lt;State\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); int cnt = 1; while (cnt \u0026lt;= stoneCount) { result.add(new State(stoneCount - cnt)); cnt = cnt \u0026lt;\u0026lt; 1; } return result; } public int getStoneCount() { return stoneCount; } public boolean isTerminated() { int cnt = 1; while (cnt \u0026lt; stoneCount) { cnt = cnt \u0026lt;\u0026lt; 1; } return cnt == stoneCount; } @Override public String toString() { return String.valueOf(stoneCount); } }  The result Now run the code\nTreeWorker worker = new TreeWorker(); Node root = worker.generateTree(new State(99)); System.out.println(root);  This will give an output similar to this for the first game: {99 | true} -\u0026gt; {96 | false} -\u0026gt; {93 | true} -\u0026gt; {92 | false} -\u0026gt; {91 | true} -\u0026gt; {88 | false} -\u0026gt; {85 | true} -\u0026gt; {84 | false} -\u0026gt; {81 | true} -\u0026gt; {80 | false} -\u0026gt; {77 | true} -\u0026gt; {76 | false} -\u0026gt; {75 | true} -\u0026gt; {72 | false} -\u0026gt; {69 | true} -\u0026gt; {68 | false} -\u0026gt; {67 | true} -\u0026gt; {64 | false} -\u0026gt; {63 | true} -\u0026gt; {60 | false} -\u0026gt; {58 | true} -\u0026gt; {56 | false} -\u0026gt; {55 | true} -\u0026gt; {52 | false} -\u0026gt; {51 | true} -\u0026gt; {48 | false} -\u0026gt; {46 | true} -\u0026gt; {44 | false} -\u0026gt; {42 | true} -\u0026gt; {40 | false} -\u0026gt; {37 | true} -\u0026gt; {36 | false} -\u0026gt; {33 | true} -\u0026gt; {32 | false} -\u0026gt; {30 | true} -\u0026gt; {28 | false} -\u0026gt; {25 | true} -\u0026gt; {24 | false} -\u0026gt; {21 | true} -\u0026gt; {20 | false} -\u0026gt; {18 | true} -\u0026gt; {16 | false} -\u0026gt; {13 | true} -\u0026gt; {12 | false} -\u0026gt; {11 | true} -\u0026gt; {8 | false} -\u0026gt; {7 | true} -\u0026gt; {4 | false} -\u0026gt; {3 | true} So, it seems that the first player has the winning strategy and will win from the initial position if he performs a perfect play. In this case the second player is desperate – having false in each of his moves shows the absence of moves leading to a victory. It is not hard to notice the pattern. Each time the second player takes 1 stone out of the pile, the first takes out 3 stones; for 2 stones – 2 stones; and for 3 stones – 1 stone. So the idea is quite clear – to win one has to keep the number of stones divisible by 4. For the second game the output is somewhat similar to the following: {99 | false} -\u0026gt; {98 | true} -\u0026gt; {66 | false} -\u0026gt; {58 | true} -\u0026gt; {54 | false} -\u0026gt; {46 | true} -\u0026gt; {30 | false} -\u0026gt; {14 | true} -\u0026gt; {6 | false} -\u0026gt; {2 | true} So, here the situation is totally different and the first player cannot win if both sides perform a perfect play. The strategy is to keep the number of stones divisible by 3.\nOutro Zermelo’s backward induction algorithm is one of the cornerstone algorithms in game theory. It is a classic example of dynamic programming, in which a solution to an overall problem is systematically built up from the solutions to smaller problems. It can be used to analyze different games from tic-tac-toe to chess. So, try it your own!\n","date":1493720100,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493720100,"objectID":"3d916d8870bfa5e8091e3cfb864a7bd8","permalink":"/post/finding-winning-strategies/","publishdate":"2017-05-02T13:15:00+03:00","relpermalink":"/post/finding-winning-strategies/","section":"post","summary":"This time I want to show how to solve a game using a perfect play which means being able to predict the outcome of the game from any position. The perfect play is the strategy that leads to the best possible outcome for that player regardless of the response by the opponent. For the illustration I have selected two children’s games with stones. The rules are very simple. There is a pile of 99 stones. Two player take n stones out of the pile in turn. The one who takes the last stone is the winner. In each game n is different:\n it is in the closed interval between 1 and 3 power of 2  Let’s find out how to always win these kind of games.\n","tags":["algorithm","backward induction","game theory","java","zermelo's theorem"],"title":"Finding winning strategies","type":"post"},{"authors":null,"categories":["DB"],"content":"Storing data in MongoDB with the official C# driver sooner or later you might run into the following exception:\nSystem.IO.FileFormatException: Size 22327168 is larger than MaxDocumentSize 16777216.  This is happening because of the limitation of a single document size that exists in MongoDB by design.\n The maximum BSON document size is 16 megabytes. The maximum document size helps ensure that a single document cannot use excessive amount of RAM or, during transmission, excessive amount of bandwidth.\n Though there is a JIRA ticket called Increase max document size to at least 64mb, it doesn’t seem likely to be done in the near future. Geert Bosch, senior software engineer at MongoDB, wrote the following comment:\n In order to support much larger documents, such as the 64Mb documents suggested, assumptions such as that we can easily allocate copies of documents for modification will no longer hold. Transactions could grow extremely large (just think of a 64Mb array of elements to index). We would need to significantly throttle the number of concurrent operations, or raise the memory requirements for mongod.\n But, if you find yourself stuck in such a situation, don’t get frustrated – there is a solution.\nExplore the document MongoDB uses JSON documents in order to store records, but stores them in a binary-encoded format called BSON. Take a look at your document. It might look somewhat similar to this:\n{ \u0026quot;Property1\u0026quot;: true, \u0026quot;Property2\u0026quot;: 123, \u0026quot;Property3\u0026quot;: \u0026quot;Hello World\u0026quot;, \u0026quot;Property4\u0026quot;: null, \u0026quot;Property5\u0026quot;: null, \u0026quot;Property6\u0026quot;: [ 1, 2, 3 ], \u0026quot;Property7\u0026quot;: [] }  With an object-oriented representation like .net objects usually store their name and the null literal for each null property. Also you may notice empty arrays. Another thing that may be tuned is the property name mapping. By default, the names of the fields in the generated JSON document are equal to those of the corresponding properties. So, the solution is to get rid of everything that is possible and shorten the names.\nThe solution Ignoring null values To ignore the null values you have at least 3 options:\n decorating properties with BsonIgnoreIfNull attribute using fluent api register a global convention  The first option lets you mark properties individually:\npublic class Class1 { public bool Property1 { get; set; } public int Property2 { get; set; } [BsonIgnoreIfNull] public string Property3 { get; set; } [BsonIgnoreIfNull] public string Property4 { get; set; } [BsonIgnoreIfNull] public string Property5 { get; set; } [BsonIgnoreIfNull] public List\u0026lt;int\u0026gt; Property6 { get; set; } [BsonIgnoreIfNull] public List\u0026lt;int\u0026gt; Property7 { get; set; } }  But it is better to keep your business entities clean, so consider the second option.\nBsonClassMap.RegisterClassMap\u0026lt;Class1\u0026gt;(x =\u0026gt; { x.AutoMap(); x.GetMemberMap(m =\u0026gt; m.Property3).SetIgnoreIfNull(true); x.GetMemberMap(m =\u0026gt; m.Property4).SetIgnoreIfNull(true); x.GetMemberMap(m =\u0026gt; m.Property5).SetIgnoreIfNull(true); x.GetMemberMap(m =\u0026gt; m.Property6).SetIgnoreIfNull(true); x.GetMemberMap(m =\u0026gt; m.Property7).SetIgnoreIfNull(true); });  But still it can add a lot of code, so you might want to introduce a global policy.\nConventionRegistry.Register( \u0026quot;Ignore null values\u0026quot;, new ConventionPack { new IgnoreIfNullConvention(true) }, t =\u0026gt; t == typeof(Class1));  The last predicate ensures the policy only applies to Class1 class. Also make sure you are registering the new convention pack early enough. If the class has already been mapped it won’t be updated.\nIgnoring empty collections It is not complicated to do with the SetShouldSerializeMethod. The specified predicate is triggered to determine whether the member should be serialized. Simply check the number of items inside the collection before saving it. Here is the code\nBsonClassMap.RegisterClassMap\u0026lt;Class1\u0026gt;(x =\u0026gt; { x.AutoMap(); x.GetMemberMap(m =\u0026gt; m.Property7).SetShouldSerializeMethod(x =\u0026gt; ((Class1)x).Property7.Count \u0026gt; 0); });  Shortening names The last and probably the most efficient way is to make each class property name shorter. Of course it affects your data readability, that is why it is not the first offered solution, but in my case it reduced the document size by two times. As usual you can use an attribute or a fluent approach. The attribute is called BsonElement.\npublic class Class1 { [BsonElement(\u0026quot;p1\u0026quot;)] public bool Property1 { get; set; } [BsonElement(\u0026quot;p2\u0026quot;)] public int Property2 { get; set; } [BsonElement(\u0026quot;p3\u0026quot;)] public string Property3 { get; set; }\t}  The following code can be used with the fluent api\nBsonClassMap.RegisterClassMap\u0026lt;Class1\u0026gt;(x =\u0026gt; { x.AutoMap(); x.GetMemberMap(m =\u0026gt; m.Property4).SetElementName(\u0026quot;p4\u0026quot;); x.GetMemberMap(m =\u0026gt; m.Property5).SetElementName(\u0026quot;p5\u0026quot;); x.GetMemberMap(m =\u0026gt; m.Property6).SetElementName(\u0026quot;p6\u0026quot;); x.GetMemberMap(m =\u0026gt; m.Property7).SetElementName(\u0026quot;p7\u0026quot;); });  Result After applying this solution you might be able to get a document that fits into the MongoDB database. Compared to the original document the result seems to save a lot of space. Consider the resulting JSON\n{ \u0026quot;p1\u0026quot;: true, \u0026quot;p2\u0026quot;: 123, \u0026quot;p3\u0026quot;: \u0026quot;Hello World\u0026quot;, \u0026quot;p6\u0026quot;: [ 1, 2, 3 ] }  I think that the difference in size is obvious. Using all three techniques allowed me to store a document that seemed too large in the beginning.\n","date":1492255020,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1492255020,"objectID":"ada1b06baa670a23cf6bb41e97b193d0","permalink":"/post/reducing-the-size-of-mongodb-document-in-cs/","publishdate":"2017-04-15T14:17:00+03:00","relpermalink":"/post/reducing-the-size-of-mongodb-document-in-cs/","section":"post","summary":"Storing data in MongoDB with the official C# driver sooner or later you might run into the following exception:\nSystem.IO.FileFormatException: Size 22327168 is larger than MaxDocumentSize 16777216.  This is happening because of the limitation of a single document size that exists in MongoDB by design.\n The maximum BSON document size is 16 megabytes. The maximum document size helps ensure that a single document cannot use excessive amount of RAM or, during transmission, excessive amount of bandwidth.\n Though there is a JIRA ticket called Increase max document size to at least 64mb, it doesn’t seem likely to be done in the near future. Geert Bosch, senior software engineer at MongoDB, wrote the following comment:\n In order to support much larger documents, such as the 64Mb documents suggested, assumptions such as that we can easily allocate copies of documents for modification will no longer hold. Transactions could grow extremely large (just think of a 64Mb array of elements to index). We would need to significantly throttle the number of concurrent operations, or raise the memory requirements for mongod.\n But, if you find yourself stuck in such a situation, don’t get frustrated – there is a solution.\n","tags":["csharp","mongodb"],"title":"Reducing the size of MongoDB document in c#","type":"post"},{"authors":null,"categories":["Go"],"content":"About a month ago we welcomed a new developer to our go-linq maintainers team cleitonmarx (Cleiton Marques) who introduced an interesting pattern for emulating generics in Go and became the main show-maker of the third version of the library. Here is a small story of how the generics behavior was emulated in go-linq.\nThe problem Being one of the most requested features in Go language for years, the question of generics has been discussed up and down and back and forth. For now it seems that they won\u0026rsquo;t appear in the near future. In fact, the language designers aren\u0026rsquo;t against generics, but they have not found or seen a good proposal that allows generics in the language without significantly complicating it. Anyway, we got used to living without generics. This resulted in a slight adjustment to our way of thinking and brought to life tons of elegant solutions. But sometimes there are situations when generics are indispensable. For example, in the go-linq library methods are intended to be used with delegates of any data type, so we made them accept functions of empty interfaces. This interface has no particular behavior, hence objects with any behavior satisfy this interface and the end user of the library is responsible for doing the right type casts. Despite its good performance, this approach isn\u0026rsquo;t use-of-wrong-data-type proof and looks clumsy. Consider the difference:\nFrom(cars).Where(func(c interface{}) bool { return c.(Car).year \u0026gt;= 2015 }).Select(func(c interface{}) interface{} { return c.(Car).owner })  vs\nFrom(cars).Where(func(c Car) bool { return c.year \u0026gt;= 2015 }).Select(func(c Car) string { return c.owner })  and it\u0026rsquo;s getting worse depending on the complexity of your code. So, we introduced a pattern for emulating/improving generics-like methods in our library that uses the reflection mechanism internally and make your code look much easier to read and understand.\nThe solution The idea is to make a new method that wraps around the original one with empty interfaces and does all the casts automatically using reflection. The second part of the solution comes from the fact that the signature to the new method is func (q Query) WhereT(predicateFn interface{}) Query , so anything can be specified as the argument and we need a way to validate it.\nFirst, let\u0026rsquo;s define a structure to store all the necessary data:\ntype functionCache struct { MethodName string ParamName string FnValue reflect.Value FnType reflect.Type TypesIn []reflect.Type TypesOut []reflect.Type } type genericFunc struct { Cache *functionCache } func (g *genericFunc) Call(params ...interface{}) interface{} { paramsIn := make([]reflect.Value, len(params)) for i, param := range params { paramsIn[i] = reflect.ValueOf(param) } paramsOut := g.Cache.FnValue.Call(paramsIn) if len(paramsOut) \u0026gt;= 1 { return paramsOut[0].Interface() } return nil }  MethodName and ParamName are used in error handling to form a reasonable message. TypesIn and TypesOut store respectively the input and output parameters of the specified function.\nSecondly, we need a factory method for the \u0026lsquo;genericFunc\u0026rsquo;:\nfunc newGenericFunc(methodName, paramName string, fn interface{}, validateFunc func(*functionCache) error) (*genericFunc, error) { cache := \u0026amp;functionCache{} cache.FnValue = reflect.ValueOf(fn) if cache.FnValue.Kind() != reflect.Func { return nil, fmt.Errorf(\u0026quot;%s: parameter [%s] is not a function type. It is a '%s'\u0026quot;, methodName, paramName, cache.FnValue.Type()) } cache.MethodName = methodName cache.ParamName = paramName cache.FnType = cache.FnValue.Type() numTypesIn := cache.FnType.NumIn() cache.TypesIn = make([]reflect.Type, numTypesIn) for i := 0; i \u0026lt; numTypesIn; i++ { cache.TypesIn[i] = cache.FnType.In(i) } numTypesOut := cache.FnType.NumOut() cache.TypesOut = make([]reflect.Type, numTypesOut) for i := 0; i \u0026lt; numTypesOut; i++ { cache.TypesOut[i] = cache.FnType.Out(i) } if err := validateFunc(cache); err != nil { return nil, err } return \u0026amp;genericFunc{Cache: cache}, nil }  it populates the genericFunc structure and validates it. The validation function must be provided by the user of the method, but we have a helper to produce it:\nfunc simpleParamValidator(In []reflect.Type, Out []reflect.Type) func(cache *functionCache) error { return func(cache *functionCache) error { var isValid = func() bool { if In != nil { if len(In) != len(cache.TypesIn) { return false } for i, paramIn := range In { if paramIn != genericTp \u0026amp;\u0026amp; paramIn != cache.TypesIn[i] { return false } } } if Out != nil { if len(Out) != len(cache.TypesOut) { return false } for i, paramOut := range Out { if paramOut != genericTp \u0026amp;\u0026amp; paramOut != cache.TypesOut[i] { return false } } } return true } if !isValid() { return fmt.Errorf( \u0026quot;%s: parameter [%s] has a invalid function signature. Expected: '%s', actual: '%s'\u0026quot;, cache.MethodName, cache.ParamName, formatFnSignature(In, Out), formatFnSignature(cache.TypesIn, cache.TypesOut)) } return nil } }  The last thing we need is the wrapper around the original method that does all the magic. For the above-mentioned Where method it is as simple as:\nfunc (q Query) WhereT(predicateFn interface{}) Query { predicateGenericFunc, err := newGenericFunc( \u0026quot;WhereT\u0026quot;, \u0026quot;predicateFn\u0026quot;, predicateFn, simpleParamValidator(newElemTypeSlice(new(genericType)), newElemTypeSlice(new(bool))), ) if err != nil { panic(err) } predicateFunc := func(item interface{}) bool { return predicateGenericFunc.Call(item).(bool) } return q.Where(predicateFunc) }  So, you provide a function with your custom types to a new WhereT method and it produces a wrapper with empty interfaces that will suffice for the original method Where.\nThe test If you are writing unit tests on your project and are pursuing a 100% coverage level, as we do in go-linq, then it is not an easy task to achieve with this pattern. After trying several approaches we ended up with writing several tests:\n one for the right case when everything is ok and the second that tests the validation, recovers the panic and checks the error message.\nfunc TestWhereT_PanicWhenPredicateFnIsInvalid(t *testing.T) { mustPanicWithError( t, \u0026quot;WhereT: parameter [predicateFn] has a invalid function signature. Expected: 'func(T)bool', actual: 'func(int)int'\u0026quot;, func() { From([]int{1, 1, 1, 2, 1, 2, 3, 4, 2}).WhereT(func(item int) int { return item + 2 }) }) } func mustPanicWithError(t *testing.T, expectedErr string, f func()) { defer func() { r := recover() err := fmt.Sprintf(\u0026quot;%s\u0026quot;, r) if err != expectedErr { t.Fatalf(\u0026quot;got=[%v] expected=[%v]\u0026quot;, err, expectedErr) } }() f() }   The downsides The first and probably the main downside of this solution is the performance penalty. Running the same scenarios that I used in one of the previous articles Manipulating data with iterators in Go we can see that this approach is around 5x-10x slower. That is why we decided to provide users with both versions of the methods leaving the original as is and calling the new ones by the -T naming convention.\nBenchmarkSelectWhereFirst-4 5000000 352 ns/op BenchmarkSelectWhereFirst_generics-4 1000000 2094 ns/op BenchmarkSum-4 50 37427788 ns/op BenchmarkSum_generics-4 3 360509066 ns/op BenchmarkZipSkipTake-4 10000000 224 ns/op BenchmarkZipSkipTake_generics-4 1000000 1265 ns/op  The second issue comes from the signature of the -T method, as you can see it accepts an empty interface, i.e. predicateFn can be literally anything.\ndecode:true\u0026quot;\u0026gt;func (q Query) WhereT(predicateFn interface{}) Query  Of course, a user of the method can have problems understanding what predicateFn should look like, especially if he is new to the library. We conducted a long discussion to deal with the problem and ended up with the idea that the best we can do is to provide really good documentation and examples of each method (thanks Cleiton for being so patient and hardworking).\nSummary Do I need generics in Go? Not really, especially with the new go:generate feature. But if you still need them, there is always a way to emulate generic behavior even though it isn\u0026rsquo;t supported by the language, either by using empty interfaces and maintaining good performance, or with the pattern shown above making the code cleaner, more readable and free of type assertions. Note. The full source code is available in genericfunc.go in our repository. Please, feel free to ask any questions.\n","date":1487957820,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1487957820,"objectID":"b1411120a6ae44f6acbe24a5e1c05836","permalink":"/post/go-linq-v3-0-emulating-generics-in-go/","publishdate":"2017-02-24T20:37:00+03:00","relpermalink":"/post/go-linq-v3-0-emulating-generics-in-go/","section":"post","summary":"About a month ago we welcomed a new developer to our go-linq maintainers team cleitonmarx (Cleiton Marques) who introduced an interesting pattern for emulating generics in Go and became the main show-maker of the third version of the library. Here is a small story of how the generics behavior was emulated in go-linq.\n","tags":["generics","go-linq","golang","linq"],"title":"go-linq v3.0: Emulating generics in Go","type":"post"},{"authors":null,"categories":["Git"],"content":"Not long ago my team moved a legacy version of our application from a different branch out into a new repository. The problem was that they had forgotten to copy tags there, so we lived without tags for quite a time, until I decided to deal with the problem and made a utility that copies matching tags from one git repository to another.\nActually, I found a solution on github which was a shell script written in ruby. But there were two issues. First, I neither had nor wanted to install ruby on my machine. Secondly, I use Windows on my office laptop. So, I decided to port the original script to Go and here is the code\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;log\u0026quot; \u0026quot;os\u0026quot; \u0026quot;os/exec\u0026quot; \u0026quot;runtime\u0026quot; \u0026quot;strings\u0026quot; ) func usage() { fmt.Println(\u0026quot;Usage: git-copy-tags \u0026lt;source-repo\u0026gt; \u0026lt;dest-repo\u0026gt; [-f]\u0026quot;) fmt.Println(\u0026quot;By default, the script is in \\\u0026quot;dry run\\\u0026quot; mode, which means that it only prints out what it would do, without actually doing it. If you are happy with the result, add -f.\u0026quot;) os.Exit(1) } func shell(cmd string) ([]byte, error) { sh := \u0026quot;sh\u0026quot; c := \u0026quot;-c\u0026quot; if runtime.GOOS == \u0026quot;windows\u0026quot; { sh = \u0026quot;cmd\u0026quot; c = \u0026quot;/c\u0026quot; } return exec.Command(sh, c, cmd).CombinedOutput() } func exe(cmd string) string { result, err := shell(cmd) if err != nil { log.Fatal(err) os.Exit(1) } return string(result) } func getTags() map[string]string { tags := exe(\u0026quot;git tag\u0026quot;) dict := make(map[string]string) for _, tag := range strings.Split(tags, \u0026quot;\\n\u0026quot;) { tag = strings.TrimSpace(tag) if len(tag) \u0026lt; 1 { continue } cmd := fmt.Sprintf(\u0026quot;git rev-list --max-count=1 %s\u0026quot;, tag) commit := strings.TrimSpace(exe(cmd)) dict[tag] = commit } return dict } func main() { if len(os.Args) \u0026lt; 3 { usage() } src := os.Args[1] dest := os.Args[2] force := false if len(os.Args) \u0026gt; 3 \u0026amp;\u0026amp; os.Args[3] == \u0026quot;-f\u0026quot; { force = true } os.Chdir(src) srcTags := getTags() os.Chdir(dest) destTags := getTags() if !force { fmt.Println(\u0026quot;Running dry, use -f to actually apply changes...\u0026quot;) } for tag, commit := range srcTags { if _, ok := destTags[tag]; !ok { cmd := fmt.Sprintf(\u0026quot;git rev-list --max-count=1 %s\u0026quot;, commit) if _, err := shell(cmd); err == nil { if force { if _, err := shell(fmt.Sprintf(\u0026quot;git tag %s %s\\n\u0026quot;, tag, commit)); err == nil { fmt.Printf(\u0026quot;Tagged %s with %s\u0026quot;, commit, tag) } else { fmt.Printf(\u0026quot;Error while tagging %s with %s\\n\u0026quot;, commit, tag) } } else { fmt.Printf(\u0026quot;Would tag %s with %s\\n\u0026quot;, commit, tag) } } } } }  Usage git-copy-tags \u0026lt;source-repo\u0026gt; \u0026lt;dest-repo\u0026gt; \\[-f\\]  By default, the script is in \u0026ldquo;dry run\u0026rdquo; mode, which means that it only prints out what it would do, without actually doing it. If you are happy with the result, add -f.\nAfter running the command with -f, make sure to run git push --tags in the destination repository.\nDownload The source code is available in the github repository. And here is a cross-compiled version for different operating systems (all 64-bit)\n Windows MacOSX Linux  Bonus. Cross compilation in Go Since Go 1.5 cross compilation is very simple. Just properly set a pair of $GOOS and $GOARCH variables and run a build process as usual. For example, on Windows it can be done in the following way:\nset GOARCH=amd64 set GOOS=linux go build  The actual list is defined in src/go/build/syslist.go and the valid combinations of $GOOS and $GOARCH are:\n  $GOOS $GOARCH   android arm   darwin 386   darwin amd64   darwin arm   darwin arm64   dragonfly amd64   freebsd 386   freebsd amd64   freebsd arm   linux 386   linux amd64   linux arm   linux arm64   linux ppc64   linux ppc64le   linux mips   linux mipsle   linux mips64   linux mips64le   netbsd 386   netbsd amd64   netbsd arm   openbsd 386   openbsd amd64   openbsd arm   plan9 386   plan9 amd64   solaris amd64   windows 386   windows amd64   ","date":1487773075,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1487773075,"objectID":"b55829c75151e32a8010f72056f2e57f","permalink":"/post/how-to-copy-tags-from-one-git-repository-to-another/","publishdate":"2017-02-22T17:17:55+03:00","relpermalink":"/post/how-to-copy-tags-from-one-git-repository-to-another/","section":"post","summary":"Not long ago my team moved a legacy version of our application from a different branch out into a new repository. The problem was that they had forgotten to copy tags there, so we lived without tags for quite a time, until I decided to deal with the problem and made a utility that copies matching tags from one git repository to another.\n","tags":["golang","git"],"title":"How to copy tags from one git repository to another","type":"post"},{"authors":null,"categories":["Go"],"content":"I am happy to announce that my go2linq (a powerful language integrated query (LINQ) library for Go) project has been merged into the go-linq\u0026rsquo;s master branch. Now it is available as the newest version of go-linq library (v2.0.0).\nAll further development will be conducted in the new repository and go2linq will remain only for compatibility reasons. Please, do not use it anymore!\nI would like to thank Ahmet Alp Balkan who has made me the maintainer of the go-linq repository and is cooperating in the further development.\nLinks  go-linq website: http://ahmetalpbalkan.github.io/go-linq/ github repository: https://github.com/ahmetalpbalkan/go-linq godoc: https://godoc.org/github.com/ahmetalpbalkan/go-linq ","date":1473517320,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1473517320,"objectID":"d672ade7b48ae1b2efa0461e390f20d5","permalink":"/post/announcement-go2linq-is-now-in-the-go-linq-repository/","publishdate":"2016-09-10T17:22:00+03:00","relpermalink":"/post/announcement-go2linq-is-now-in-the-go-linq-repository/","section":"post","summary":"I am happy to announce that my go2linq (a powerful language integrated query (LINQ) library for Go) project has been merged into the go-linq\u0026rsquo;s master branch. Now it is available as the newest version of go-linq library (v2.0.0).\n","tags":["go-linq","go2linq"],"title":"Announcement: go2linq is now in the go-linq repository","type":"post"},{"authors":null,"categories":["Algorithms"],"content":"I have come across an interesting problem. A customer is standing at the checkout of a grocery store with his purchases and is asked to pay the exact amount without creating any change. There are notes of various denominations in his pockets in random order (note denomination is not tied to a real bank notes, the only boundary is that it is an integer greater than 0). The objective is to pick up the necessary sum or indicate that it is not possible. If several solutions are possible then any of them is acceptable. So, let's solve it using C# language.\nThis problem is a special case of the knapsack problem (given a set of items, each with a weight and a value, determine the number of each item to include in a collection so that the total weight is less than or equal to a given limit and the total value is as large as possible) and is equivalent to a subset sum problem (finding a non-empty subset whose sum is zero) with an extra condition that each element of the set is strictly greater than zero. As it is an NP-complete problem I can think of 2 possible ways to solve it. Let's first discuss the recursive approach and then improve it using dynamic programming.\nRecursive Approach This is the most naive algorithm. For every element in the set there are two options, either we will include that element in the subset or we won’t include it. Then cycle through all these subsets and, for every one of them, check if the subset sum equals the right number. This solution is quite similar to generating all strings of n bits and its time complexity is as high as O(n*2n), since there are 2n subsets and for each subset we need to sum n elements.\nLet's improve it a bit. First optimization comes from the idea that we do not really need to calculate all the possible subsets and calculate all the sums afterward. Instead we can merge these two steps in a single operation and have a means to restore the set that produced the right sum. Having a set A of elements {a1, a2, a3 ... an} let's build a tree of all possible sums until we find a target sum S. Let's start with adding 0 to the tree and then adding each element of A to all the elements in this tree.    a1 a2 a3 ... an  0 0+a1 0+a2 0+a3 ... 0+an      (0+a1)+a2 (0+a1)+a3 ...  (0+a1)+an        (0+a2)+a3 ...  (0+a2)+an        ((0+a1)+a2)+a3 ... ((0+a1)+a2)+an            …            (((0+a1)+a2)+a3)+…+an   \nAs you can see now, no extra step is needed to sum each subset, instead each level of the tree uses sums from the previous tiers. So, there is 1 sum for the 1st element, 2 sums for the 2nd, 4 sums for the 3rd, 8 sums for the 4th, etc. This forms a geometrical progression with the total of \\(\\frac {1(1-2^n)}{1-2} = 2^n-1\\) elements. Now this method's complexity is O(2n).\nSecondly, we can utilize the boundary condition. As we know that all the elements in the set are positive, it is obvious that adding a new element to the set only increases the current sum. So, if the current sum of the node is higher than the target sum this solution becomes rejected and is not used in further computations. This decreases the complexity to O(2n) in the worst case. Also we can benefit from sorting the set in the descending order, because this will help to reject more solutions in the early stage. Here is the code:\npublic static List\u0026lt;int\u0026gt; FindRecursive(int[] set, int targetSum, int currentSum, int currentIndex) { for (var i = currentIndex; i \u0026lt; set.Length; i++) { var newSum = currentSum + set[i]; if (newSum \u0026gt; targetSum) { continue; } if (newSum == targetSum) { return new List\u0026lt;int\u0026gt; { set[i] }; } var result = FindRecursive(set, targetSum, newSum, i + 1); if (result == null) { continue; } result.Add(set[i]); return result; } return null; } public static void Main(string[] args) { const int sum = 47; var set = new[] { 100, 40, 5, 1, 1, 1, 1 }; var result = FindRecursive(set, sum, 0, 0); Console.WriteLine( result?.Select(x =\u0026gt; x.ToString()).Aggregate((x, y) =\u0026gt; x + \u0026quot;,\u0026quot; + y) ?? \u0026quot;null\u0026quot;); }  Dynamic programming This problem can be solved in pseudo-polynomial time using dynamic programming (a method for solving a complex problem by breaking it down into a collection of simpler subproblems). Define the boolean-valued function Q(n, s) so that:\n Q(n, 0) = true (return empty set) Q(0, s) = false, if s \u0026gt; 0 (you can't pick a positive sum with an empty set)  Then all other cases are: Q(n, s) = Q(n-1, s) || Q(n-1, s-aₙ). The only thing left is to fill the array of values of Q(i, s) for 1 ≤ i ≤ n using a simple recursion. The complexity of this method is O(n*s) which is linear.\nLet's see how it works in the example: Given a set A {1, 2, 5, 7}, is there subset whose sum is 9?\n Sum of 0 can be picked for any n with an empty set, the only sum that can be picked with an empty set is 0.    0 1 2 3 4 5 6 7 8 9   0 true false false false false false false false false false   1 true            2 true            5 true            7 true            \n Adding 1 to the set we can now pick a sum of 1.    0 1 2 3 4 5 6 7 8 9   0 true false false false false false false false false false   1 true true false false false false false false false false   2 true            5 true            7 true            \n Adding 2 to the set we can now pick a sum of 2 and 3 and we already can pick 1.    0 1 2 3 4 5 6 7 8 9   0 true false false false false false false false false false   1 true true false false false false false false false false   2 true true true true false false false false false false   5 true            7 true            \n Complete the table. Here is the answer shown in red.    0 1 2 3 4 5 6 7 8 9   0 true false false false false false false false false false   1 true true false false false false false false false false   2 true true true true false false false false false false   5 true true true true false true true true true false   7 true true true true false true true true true true   \n How to restore the set. We got the correct answer after adding 7 to the set, so let's remove it: 9-7=2. We got a sum of 2 after adding 2 to the set, so let's remove it. Now we are at the sum of 0, so the restoration is over. The track is shown in yellow.    0 1 2 3 4 5 6 7 8 9   0 true false false false false false false false false false   1 true true false false false false false false false false   2 true true true true false false false false false false   5 true true true true false true true true true false   7 true true true true false true true true true true   \n  And finally, here is the code:\npublic static List\u0026lt;int\u0026gt; FindDP(int[] set, int sum) { var solution = new bool[set.Length + 1, sum + 1]; for (var i = 0; i \u0026lt;= set.Length; i++) { solution[i, 0] = true; } for (var i = 1; i \u0026lt;= set.Length; i++) { for (var j = 1; j \u0026lt;= sum; j++) { solution[i, j] = solution[i - 1, j]; if (!solution[i, j] \u0026amp;\u0026amp; j \u0026gt;= set[i - 1]) { solution[i, j] = solution[i, j] || solution[i - 1, j - set[i - 1]]; } } if (!solution[i, sum]) { continue; } var result = new List\u0026lt;int\u0026gt;(); var q = sum; for (var p = i - 1; p \u0026gt;= 0; p--) { if (solution[p, q]) { continue; } var s = set[p]; result.Add(s); q -= s; } return result; } return null; }  PS Solving this task I've started thinking about making a github repo for such algorithms, so that one can easily find an implementation of a needed algorithm in c# or simply use it without needing to reinvent the wheel.\n","date":1469910060,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1469910060,"objectID":"d4297c0cd5d2b83bb862e421df486662","permalink":"/post/solving-a-payment-without-change-problem/","publishdate":"2016-07-30T23:21:00+03:00","relpermalink":"/post/solving-a-payment-without-change-problem/","section":"post","summary":"I have come across an interesting problem. A customer is standing at the checkout of a grocery store with his purchases and is asked to pay the exact amount without creating any change. There are notes of various denominations in his pockets in random order (note denomination is not tied to a real bank notes, the only boundary is that it is an integer greater than 0). The objective is to pick up the necessary sum or indicate that it is not possible. If several solutions are possible then any of them is acceptable. So, let's solve it using C# language.\n","tags":["algorithm","csharp","dynamic programming","subset sum problem"],"title":"Solving a payment without change problem","type":"post"},{"authors":null,"categories":["Go"],"content":"Several months ago I started learning Go language and came across an interesting library go-linq which is an implementation of Microsoft’s LINQ technology in Go. And while it is a good library I find its performance to be really weak because of its design. Trying to improve the situation resulted in a complete rewrite using iterators in a lightweight and simple manner.\ngo-linq The key type there is Query:\ntype Query struct { values []T err error }  It stores all the data in its values field and is a receiver for all the methods defined to manipulate data. Each time a method is executed it generates a new Query with a new values slice. So, for example, a Where() method can be implemented as simply as:\nfunc (q Query) Where(f func(T) (bool, error)) (r Query) { for _, i := range q.values { ok, err := f(i) if err != nil { r.err = err return r } if ok { r.values = append(r.values, i) } } return }  And although it generally is a good idea, it has poor performance for several reasons. First, each method allocates a new slice, so when you chain methods (as you normally do in linq), like From(slice).Where(wat).Select(dat) , a lot of slices are created. This results in redundant memory traffic and additional garbage collection. Secondly, since it is a push model, each method manipulates the whole collection, even if there is only a single element needed in the end, e. g. From(slice).Where(wat).First() . In this case the wat predicate is executed for each element in the slice even if First() takes a single item.\nIterator approach In order to get rid of the problems shown above, I decided to rewrite the library from scratch using the iterator pattern. Iterator is a design pattern which is used to traverse a container and access the container\u0026rsquo;s elements. It decouples algorithms from containers, which is exactly what is needed to achieve a pull model, so that the predicate in the previous example can be executed only for the elements that are really needed. According to the Gang of Four iterator prescribes the following interface for iteration over a container with elements of type T:\ninterface Iterator { void First(); // Restart iteration void Next(); // Advance to next item bool IsDone(); // Are we done yet? T CurrentItem(); // Get current item }  In C# (where LINQ originated) iterator is called an Enumerator and implements the following interface:\npublic interface IEnumerator { object Current { get; } bool MoveNext(); void Reset(); }  But as Go is about simplicity, I wanted my iterators to be as lightweight as possible. So decided to omit the Reset() method (as it is not really needed in LINQ) and benefit from Go\u0026rsquo;s ability to return multiple values. So I ended with the following pattern:\ntype Iterator func() (item interface{}, ok bool) type Query struct { Iterate func() Iterator } next := query.Iterate() for item, ok := next(); ok; item, ok = next() { fmt.Println(item) }  Now it became really simple to work with. Each time next() is called it returns the next element of the container and the boolean value indicating whether this element exists. Now the Where() method mentioned above can be rewritten in this way:\nfunc (q Query) Where(predicate func(interface{}) bool) Query { return Query{ Iterate: func() Iterator { next := q.Iterate() return func() (item interface{}, ok bool) { for item, ok = next(); ok; item, ok = next() { if predicate(item) { return } } return } }, } }  Now Where() doesn\u0026rsquo;t really process anything, instead it generates a new iterator that will manipulate data only when it is iterated.\nBenchmark Rewriting each method to use iterators instead of slices increased the performance dramatically. For example, talking about the previously mentioned case From(slice).Where(wat).First() the source slice now is scanned only until the first element that satisfies the wat condition is found. Another good thing is that it allocates no additional memory. Lets make a simple benchmark comparing the iterators approach to go-linq\u0026rsquo;s:\nconst ( size = 1000000 ) func BenchmarkSelectWhereFirst(b *testing.B) { for n := 0; n \u0026lt; b.N; n++ { Range(1, size).Select(func(i interface{}) interface{} { return -i.(int) }).Where(func(i interface{}) bool { return i.(int) \u0026gt; -1000 }).First() } } func BenchmarkSelectWhereFirst_golinq(b *testing.B) { for n := 0; n \u0026lt; b.N; n++ { golinq.Range(1, size).Select(func(a golinq.T) (golinq.T, error) { return -a.(int), nil }).Where(func(a golinq.T) (bool, error) { return a.(int) \u0026gt; -1000, nil }).First() } } func BenchmarkSum(b *testing.B) { for n := 0; n \u0026lt; b.N; n++ { Range(1, size).Where(func(i interface{}) bool { return i.(int)%2 == 0 }).SumInts() } } func BenchmarkSum_golinq(b *testing.B) { for n := 0; n \u0026lt; b.N; n++ { golinq.Range(1, size).Where(func(a golinq.T) (bool, error) { return a.(int)%2 == 0, nil }).Sum() } } func BenchmarkZipSkipTake(b *testing.B) { for n := 0; n \u0026lt; b.N; n++ { Range(1, size).Zip(Range(1, size).Select(func(i interface{}) interface{} { return i.(int) * 2 }), func(i, j interface{}) interface{} { return i.(int) + j.(int) }).Skip(2).Take(5) } } func BenchmarkZipSkipTake_golinq(b *testing.B) { for n := 0; n \u0026lt; b.N; n++ { golinq.Range(1, size).Zip(golinq.Range(11, size).Select(func(i golinq.T) (golinq.T, error) { return i.(int) * 2, nil }), func(i, j golinq.T) (golinq.T, error) { return i.(int) + j.(int), nil }).Skip(2).Take(5) } }  The result of this benchmark on my machine (MacBookPro8,1 Intel Core i5 2,4 GHz):\nBenchmarkSelectWhereFirst-4 3000000 561 ns/op 224 B/op 10 allocs/op BenchmarkSelectWhereFirst_golinq-4 2 555810859 ns/op 120546360 B/op 2000085 allocs/op BenchmarkSum-4 20 73847428 ns/op 8000289 B/op 1000019 allocs/op BenchmarkSum_golinq-4 5 253731714 ns/op 69161392 B/op 1000053 allocs/op BenchmarkZipSkipTake-4 5000000 351 ns/op 192 B/op 6 allocs/op BenchmarkZipSkipTake_golinq-4 2 672403213 ns/op 144520824 B/op 3000075 allocs/op  Resume As you can see using this technique you can easily implement methods with lazy execution which seriously outperform a more straightforward and immediate execution. I have already implemented all the methods from traditional LINQ. This work can be found in my github repository go2linq. Feel free to use it, ask for improvements or implement new methods.\n","date":1468702380,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1468702380,"objectID":"3ada3a0a4e7942cde31050809c45a506","permalink":"/post/manipulating-data-with-iterators-in-go/","publishdate":"2016-07-16T23:53:00+03:00","relpermalink":"/post/manipulating-data-with-iterators-in-go/","section":"post","summary":"Several months ago I started learning Go language and came across an interesting library go-linq which is an implementation of Microsoft’s LINQ technology in Go. And while it is a good library I find its performance to be really weak because of its design. Trying to improve the situation resulted in a complete rewrite using iterators in a lightweight and simple manner.\n","tags":["go-linq","go2linq","golang","iterator","linq"],"title":"Manipulating Data With Iterators in Go","type":"post"}]